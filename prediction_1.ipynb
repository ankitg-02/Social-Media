{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression,ElasticNet,ElasticNetCV,Ridge,RidgeCV,Lasso,LassoCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import OrdinalEncoder,LabelEncoder\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error,root_mean_squared_error\n",
    "import xgboost as xgbss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import seaborn as sns # type: ignore\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    filename='prediction.log',\n",
    "    filemode='w',\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s-%(name)s-%(levelname)s-%(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "social=pd.read_csv(r'Time-Wasters on Social Media.csv')\n",
    "data=pd.DataFrame(social)\n",
    "logging.info('retrieving the data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.debug('modification of data')\n",
    "mod_data=data.drop(columns=['UserID','Video ID','Location','Watch Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mod_data.columns:\n",
    "    if mod_data[i].dtype=='int':\n",
    "        q3=mod_data[i].quantile(0.75)\n",
    "        q1=mod_data[i].quantile(0.25)\n",
    "        iqr=q3-q1\n",
    "        lower_bound=q1-1.5*iqr\n",
    "        upper_bound=q3+1.5*iqr\n",
    "        mod_data[(mod_data[i]>=lower_bound) & (mod_data[i]<=upper_bound)]\n",
    "        \n",
    "    elif mod_data[i].dtype=='float':\n",
    "        q3=mod_data[i].quantile(0.75)\n",
    "        q1=mod_data[i].quantile(0.25)\n",
    "        iqr=q3-q1\n",
    "        lower_bound=q1-1.5*iqr\n",
    "        upper_bound=q3+1.5*iqr\n",
    "        mod_data[(mod_data[i]>=lower_bound) & (mod_data[i]<=upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mod_data.columns:\n",
    "    if mod_data[i].dtype=='object':\n",
    "        print(mod_data[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_data['Demographics']=mod_data['Demographics'].replace({'Rural':0,'Urban':1}).astype('int')\n",
    "mod_data['Gender']=mod_data['Gender'].replace({'Male':1,'Female':2,'Other':3}).astype('int')\n",
    "mod_data['ConnectionType']=mod_data['ConnectionType'].replace({'Mobile Data':1,'Wi-Fi':2}).astype('int')\n",
    "mod_data['Profession']=mod_data['Profession'].replace({'Students':1,'Waiting staff':2,\n",
    "                                                       'Labor/Worker':3,'driver':4,'Engineer':5,\n",
    "                                                       'Cashier':6,'Manager':7,'Artist':8\n",
    "                                                       ,'Teacher':9}).astype('int')\n",
    "mod_data['Platform']=mod_data['Platform'].replace({'TikTok':1,'Instagram':2\n",
    "                                                  ,'YouTube':3,'Facebook':4}).astype('int')\n",
    "mod_data['DeviceType']=mod_data['DeviceType'].replace({'Smartphone':1,'Tablet':2\n",
    "                                                       ,'Computer':3}).astype('int')\n",
    "mod_data['Watch Reason']=mod_data['Watch Reason'].replace({'Habit':1,'Boredom':2,\n",
    "                                                           'Entertainment':3,'Procrastination':4}).astype('int')\n",
    "mod_data['CurrentActivity']=mod_data['CurrentActivity'].replace({'At home':1,\n",
    "                                                                 'At school':2,\n",
    "                                                                 'At work':3,\n",
    "                                                                 'Commuting':4}).astype('int')\n",
    "mod_data['Frequency']=mod_data['Frequency'].replace({'Evening':1,'Night':2,'Afternoon':3\n",
    "                                                     ,'Morning':4}).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_data['Video Category']=mod_data['Video Category'].replace({'Jokes/Memes':1,\n",
    "                                                               'Life Hacks':2,\n",
    "                                                               'Gaming':3,\n",
    "                                                               'Vlogs':4,\n",
    "                                                               'Pranks':5,\n",
    "                                                               'Entertainment':6,\n",
    "                                                               'Trends':7,\n",
    "                                                               'ASMR':8,\n",
    "                                                               'Comedy':9}).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=mod_data.drop(columns=['Debt','Owns Property','Demographics','Video Length',\n",
    "                         'Importance Score','Watch Reason','OS','Satisfaction'],axis=1)\n",
    "y=mod_data['Satisfaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.4,stratify=y,random_state=1)\n",
    "x_train1,x_val,y_train1,y_val=train_test_split(x_test,y_test,test_size=0.5,stratify=y,random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The test size of independent variables is={x_test.shape}')\n",
    "print(f'The test size of dependent variables is={y_test.shape}')\n",
    "print(f'The train size of independent variables is={x_train.shape}')\n",
    "print(f'The train size of dependent variables is={y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The test size of independent variables is={x_val.shape}')\n",
    "print(f'The test size of dependent variables is={y_val.shape}')\n",
    "print(f'The train size of independent variables is={x_train1.shape}')\n",
    "print(f'The train size of dependent variables is={y_train1.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=StandardScaler()\n",
    "x_train_scaled=s.fit_transform(x_train)\n",
    "x_test_scaled=s.fit_transform(x_test)\n",
    "x_val_scaled=s.fit_transform(x_val)\n",
    "x_train1_scaled=s.fit_transform(x_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinearRegression\n",
    "lr=LinearRegression()\n",
    "lr1=LinearRegression()\n",
    "lr.fit(x_train_scaled,y_train)\n",
    "lr1.fit(x_train1_scaled,y_train1)\n",
    "pred_1=lr.predict(x_test_scaled)\n",
    "pred_11=lr1.predict(x_val_scaled)\n",
    "data_test_lr={'original data':y_test,\n",
    "         'test case prediction':pred_1,}\n",
    "df_test_lr=pd.DataFrame(data_test_lr)\n",
    "\n",
    "print(df_test_lr.head())\n",
    "\n",
    "print(f'mean absolute error for test case ={mean_absolute_error(y_test,pred_1)}')\n",
    "print(f'mean squared error for test case ={mean_squared_error(y_test,pred_1)}')\n",
    "print(f'root mean squared error for test case ={root_mean_squared_error(y_test,pred_1)}')\n",
    "print(f'r2 score for test case ={r2_score(y_test,pred_1)}')\n",
    "\n",
    "\n",
    "data_val_lr={'original data':y_val,\n",
    "         'validate case prediction':pred_11,}\n",
    "df_val_lr=pd.DataFrame(data_val_lr)\n",
    "#print(df_val_lr)\n",
    "\n",
    "print(df_val_lr.head())\n",
    "\n",
    "\n",
    "print(f'mean absolute error for validate case ={mean_absolute_error(y_val,pred_11)}')\n",
    "print(f'mean squared error for validate case ={mean_squared_error(y_val,pred_11)}')\n",
    "print(f'root mean squared error for test case ={root_mean_squared_error(y_val,pred_11)}')\n",
    "print(f'r2 score for tesvalidatet case ={r2_score(y_val,pred_11)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge\n",
    "rr=Ridge()\n",
    "rrcv=RidgeCV(cv=4)\n",
    "rr.fit(x_train_scaled,y_train)\n",
    "rrcv.fit(x_train1_scaled,y_train1)\n",
    "pred_1_2=rr.predict(x_test_scaled)\n",
    "pred_11_2=rrcv.predict(x_val_scaled)\n",
    "data_test_rr={'original data':y_test,\n",
    "         'test case prediction':pred_1_2,}\n",
    "df_test_rr=pd.DataFrame(data_test_rr)\n",
    "\n",
    "print(df_test_rr.head())\n",
    "\n",
    "print(f'mean absolute error for test case ={mean_absolute_error(y_test,pred_1_2)}')\n",
    "print(f'mean squared error for test case ={mean_squared_error(y_test,pred_1_2)}')\n",
    "print(f'root mean squared error for test case ={root_mean_squared_error(y_test,pred_1_2)}')\n",
    "print(f'r2 score for test case ={r2_score(y_test,pred_1_2)}')\n",
    "\n",
    "\n",
    "data_val_rr={'original data':y_val,\n",
    "         'validate case prediction':pred_11_2,}\n",
    "df_val_rr=pd.DataFrame(data_val_rr)\n",
    "#print(df_val_lr)\n",
    "\n",
    "print(df_val_rr.head())\n",
    "\n",
    "\n",
    "print(f'mean absolute error for validate case ={mean_absolute_error(y_val,pred_11_2)}')\n",
    "print(f'mean squared error for validate case ={mean_squared_error(y_val,pred_11_2)}')\n",
    "print(f'root mean squared error for validate case ={root_mean_squared_error(y_val,pred_11_2)}')\n",
    "print(f'r2 score for validate case ={r2_score(y_val,pred_11_2)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso\n",
    "l=Lasso()\n",
    "lcv=LassoCV(cv=4)\n",
    "l.fit(x_train_scaled,y_train)\n",
    "lcv.fit(x_train1_scaled,y_train1)\n",
    "pred_1_3=l.predict(x_test_scaled)\n",
    "pred_11_3=l.predict(x_val_scaled)\n",
    "data_test_l={'original data':y_test,\n",
    "         'test case prediction':pred_1_3,}\n",
    "df_test_l=pd.DataFrame(data_test_l)\n",
    "\n",
    "print(df_test_l.head())\n",
    "\n",
    "print(f'mean absolute error for test case ={mean_absolute_error(y_test,pred_1_3)}')\n",
    "print(f'mean squared error for test case ={mean_squared_error(y_test,pred_1_3)}')\n",
    "print(f'root mean squared error for test case ={root_mean_squared_error(y_test,pred_1_3)}')\n",
    "print(f'r2 score for test case ={r2_score(y_test,pred_1_3)}')\n",
    "\n",
    "\n",
    "data_val_l={'original data':y_val,\n",
    "         'validate case prediction':pred_11_3,}\n",
    "df_val_l=pd.DataFrame(data_val_l)\n",
    "#print(df_val_lr)\n",
    "\n",
    "print(df_val_lr.head())\n",
    "\n",
    "\n",
    "print(f'mean absolute error for validate case ={mean_absolute_error(y_val,pred_11_3)}')\n",
    "print(f'mean squared error for validate case ={mean_squared_error(y_val,pred_11_3)}')\n",
    "print(f'root mean squared error for validate case ={root_mean_squared_error(y_val,pred_11_3)}')\n",
    "print(f'r2 score for validate case ={r2_score(y_val,pred_11_3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ElasticNet\n",
    "el=ElasticNet()\n",
    "elcv=ElasticNetCV(cv=3,l1_ratio=0.95)\n",
    "el.fit(x_train_scaled,y_train)\n",
    "elcv.fit(x_train1_scaled,y_train1)\n",
    "pred_1_4=el.predict(x_test_scaled)\n",
    "pred_11_4=elcv.predict(x_val_scaled)\n",
    "data_test_el={'original data':y_test,\n",
    "         'test case prediction':pred_1_4,}\n",
    "df_test_el=pd.DataFrame(data_test_el)\n",
    "\n",
    "print(df_test_el.head())\n",
    "\n",
    "print(f'mean absolute error for test case ={mean_absolute_error(y_test,pred_1_4)}')\n",
    "print(f'mean squared error for test case ={mean_squared_error(y_test,pred_1_4)}')\n",
    "print(f'root mean squared error for test case ={root_mean_squared_error(y_test,pred_1_4)}')\n",
    "print(f'r2 score for test case ={r2_score(y_test,pred_1)}')\n",
    "\n",
    "\n",
    "data_val_el={'original data':y_val,\n",
    "         'validate case prediction':pred_11_4,}\n",
    "df_val_el=pd.DataFrame(data_val_el)\n",
    "#print(df_val_lr)\n",
    "\n",
    "print(df_val_el.head())\n",
    "\n",
    "\n",
    "print(f'mean absolute error for validate case ={mean_absolute_error(y_val,pred_11_4)}')\n",
    "print(f'mean squared error for validate case ={mean_squared_error(y_val,pred_11_4)}')\n",
    "print(f'root mean squared error for validate case ={root_mean_squared_error(y_val,pred_11_4)}')\n",
    "print(f'r2 score for validate case ={r2_score(y_val,pred_11_4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecisionTreeRegressor\n",
    "dt=DecisionTreeRegressor()\n",
    "dt1=DecisionTreeRegressor(max_features=7,max_depth=5,criterion='friedman_mse',splitter='random')\n",
    "dt.fit(x_train_scaled,y_train)\n",
    "dt1.fit(x_train1_scaled,y_train1)\n",
    "pred_2=dt.predict(x_test_scaled)\n",
    "pred_22=dt1.predict(x_val_scaled)\n",
    "data_test_dt={'original data':y_test,\n",
    "         'test case prediction':pred_2}\n",
    "df_test_dt=pd.DataFrame(data_test_dt)\n",
    "\n",
    "print(df_test_dt.head())\n",
    "\n",
    "print(f'mean absolute error for test case ={mean_absolute_error(y_test,pred_2)}')\n",
    "print(f'mean squared error for test case ={mean_squared_error(y_test,pred_2)}')\n",
    "print(f'root mean squared error for test case ={root_mean_squared_error(y_test,pred_2)}')\n",
    "print(f'r2 score for test case ={r2_score(y_test,pred_2)}')\n",
    "\n",
    "\n",
    "data_val_dt={'original data':y_val,\n",
    "         'validate case prediction':pred_22}\n",
    "df_val_dt=pd.DataFrame(data_val_dt)\n",
    "#print(df_val_lr)\n",
    "\n",
    "print(df_val_lr.head())\n",
    "\n",
    "\n",
    "print(f'mean absolute error for validate case ={mean_absolute_error(y_val,pred_22)}')\n",
    "print(f'mean squared error for validate case ={mean_squared_error(y_val,pred_22)}')\n",
    "print(f'root mean squared error for validate case ={root_mean_squared_error(y_val,pred_22)}')\n",
    "print(f'r2 score for validate case ={r2_score(y_val,pred_22)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestRegressor\n",
    "rf=RandomForestRegressor()\n",
    "rf1=RandomForestRegressor(max_depth=10,n_estimators=220,max_features=7,criterion='friedman_mse',bootstrap=True,\n",
    "                          oob_score=True,random_state=30)\n",
    "rf.fit(x_train_scaled,y_train)\n",
    "rf1.fit(x_train1_scaled,y_train1)\n",
    "pred_3=rf.predict(x_test_scaled)\n",
    "pred_33=rf1.predict(x_val_scaled)\n",
    "data_test_rf={'original data':y_test,\n",
    "         'test case prediction':pred_3}\n",
    "df_test_rf=pd.DataFrame(data_test_rf)\n",
    "\n",
    "print(df_test_rf.head())\n",
    "\n",
    "print(f'mean absolute error for test case ={mean_absolute_error(y_test,pred_3)}')\n",
    "print(f'mean squared error for test case ={mean_squared_error(y_test,pred_3)}')\n",
    "print(f'root mean squared error for test case ={root_mean_squared_error(y_test,pred_3)}')\n",
    "print(f'r2 score for test case ={r2_score(y_test,pred_3)}')\n",
    "\n",
    "\n",
    "data_val_rf={'original data':y_val,\n",
    "         'validate case prediction':pred_33}\n",
    "df_val_rf=pd.DataFrame(data_val_rf)\n",
    "#print(df_val_lr)\n",
    "\n",
    "print(df_val_rf.head())\n",
    "\n",
    "\n",
    "print(f'mean absolute error for validate case ={mean_absolute_error(y_val,pred_33)}')\n",
    "print(f'mean squared error for validate case ={mean_squared_error(y_val,pred_33)}')\n",
    "print(f'root mean squared error for validate case ={root_mean_squared_error(y_val,pred_33)}')\n",
    "print(f'r2 score for validate case ={r2_score(y_val,pred_33)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoostRegressor\n",
    "adb=AdaBoostRegressor()\n",
    "adb1=AdaBoostRegressor()\n",
    "adb.fit(x_train_scaled,y_train)\n",
    "adb1.fit(x_train1_scaled,y_train1)\n",
    "pred_4=adb.predict(x_test_scaled)\n",
    "pred_44=adb1.predict(x_val_scaled)\n",
    "data_test_adb={'original data':y_test,\n",
    "         'test case prediction':pred_4}\n",
    "df_test_adb=pd.DataFrame(data_test_adb)\n",
    "\n",
    "print(df_test_adb.head())\n",
    "\n",
    "print(f'mean absolute error for test case ={mean_absolute_error(y_test,pred_4)}')\n",
    "print(f'mean squared error for test case ={mean_squared_error(y_test,pred_4)}')\n",
    "print(f'root mean squared error for test case ={root_mean_squared_error(y_test,pred_4)}')\n",
    "print(f'r2 score for test case ={r2_score(y_test,pred_4)}')\n",
    "\n",
    "\n",
    "data_val_adb={'original data':y_val,\n",
    "         'validate case prediction':pred_44}\n",
    "df_val_adb=pd.DataFrame(data_val_adb)\n",
    "#print(df_val_lr)\n",
    "\n",
    "print(df_val_adb.head())\n",
    "\n",
    "\n",
    "print(f'mean absolute error for validate case ={mean_absolute_error(y_val,pred_44)}')\n",
    "print(f'mean squared error for validate case ={mean_squared_error(y_val,pred_44)}')\n",
    "print(f'root mean squared error for validate case ={root_mean_squared_error(y_val,pred_44)}')\n",
    "print(f'r2 score for validate case ={r2_score(y_val,pred_44)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GradientBoostingRegressor\n",
    "gb=GradientBoostingRegressor()\n",
    "gb1=GradientBoostingRegressor()\n",
    "gb.fit(x_train_scaled,y_train)\n",
    "gb1.fit(x_train1_scaled,y_train1)\n",
    "pred_5=gb.predict(x_test_scaled)\n",
    "pred_55=gb.predict(x_val_scaled)\n",
    "data_test_gb={'original data':y_test,\n",
    "         'test case prediction':pred_5}\n",
    "df_test_gb=pd.DataFrame(data_test_gb)\n",
    "\n",
    "print(df_test_gb.head())\n",
    "\n",
    "print(f'mean absolute error for test case ={mean_absolute_error(y_test,pred_5)}')\n",
    "print(f'mean squared error for test case ={mean_squared_error(y_test,pred_5)}')\n",
    "print(f'root mean squared error for test case ={root_mean_squared_error(y_test,pred_5)}')\n",
    "print(f'r2 score for test case ={r2_score(y_test,pred_5)}')\n",
    "\n",
    "\n",
    "data_val_gb={'original data':y_val,\n",
    "         'validate case prediction':pred_55}\n",
    "df_val_gb=pd.DataFrame(data_val_gb)\n",
    "#print(df_val_lr)\n",
    "\n",
    "print(df_val_lr.head())\n",
    "\n",
    "\n",
    "print(f'mean absolute error for validate case ={mean_absolute_error(y_val,pred_55)}')\n",
    "print(f'mean squared error for validate case ={mean_squared_error(y_val,pred_55)}')\n",
    "print(f'root mean squared error for validate case ={root_mean_squared_error(y_val,pred_55)}')\n",
    "print(f'r2 score for validate case ={r2_score(y_val,pred_55)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGradientBoostingRegressor\n",
    "xgb=xgb.XGBRegressor()\n",
    "#xgb1=xgb.XGBRegressor()\n",
    "xgb.fit(x_train_scaled,y_train)\n",
    "xgb.fit(x_train1_scaled,y_train1)\n",
    "pred_6=xgb.predict(x_test_scaled)\n",
    "pred_66=xgb.predict(x_val_scaled)\n",
    "data_test_xgb={'original data':y_test,\n",
    "         'test case prediction':pred_6}\n",
    "df_test_xgb=pd.DataFrame(data_test_xgb)\n",
    "\n",
    "print(df_test_xgb.head())\n",
    "\n",
    "print(f'mean absolute error for test case ={mean_absolute_error(y_test,pred_6)}')\n",
    "print(f'mean squared error for test case ={mean_squared_error(y_test,pred_6)}')\n",
    "print(f'root mean squared error for test case ={root_mean_squared_error(y_test,pred_6)}')\n",
    "print(f'r2 score for test case ={r2_score(y_test,pred_6)}')\n",
    "\n",
    "\n",
    "data_val_xgb={'original data':y_val,\n",
    "         'validate case prediction':pred_66}\n",
    "df_val_xgb=pd.DataFrame(data_val_xgb)\n",
    "#print(df_val_lr)\n",
    "\n",
    "print(df_val_xgb.head())\n",
    "\n",
    "\n",
    "print(f'mean absolute error for validate case ={mean_absolute_error(y_val,pred_66)}')\n",
    "print(f'mean squared error for validate case ={mean_squared_error(y_val,pred_66)}')\n",
    "print(f'root mean squared error for validate case ={root_mean_squared_error(y_val,pred_66)}')\n",
    "print(f'r2 score for validate case ={r2_score(y_val,pred_66)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1_pkl=pickle.dump(rf1,open('random_forest.pkl','wb'))\n",
    "ss_pkl=pickle.dump(s,open('standard_scaler.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
